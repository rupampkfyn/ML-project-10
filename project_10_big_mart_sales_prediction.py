# -*- coding: utf-8 -*-
"""Project 10. Big Mart Sales Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qv3wNJT_SjxvN3mQ-M2EvGP1khiN_Bi9

Importing the Dependencies
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
from sklearn import metrics

"""Data Collection and Analysis"""

# loading the csv data into pandas dataframe
bigmart_data = pd.read_csv('/content/Train.csv')

# printing the first 5 rows of the dataset
bigmart_data.head()

# number of data points and number Features
bigmart_data.shape

# getting some informations about the dataset
bigmart_data.info()

"""Catagorical Featues:
- Item_Identifier
- Item_Fat_Content
- Item_Type
- Outlet_Identifier
- Outlet_Size
- Outlet_Location_Type
- Outlet_Type
"""

# Checking for missing values
bigmart_data.isnull().sum()

"""Handling the Missing Values

Mean --> Average Value

Mode --> Most repeated Value
"""

# mean value of 'Item_Weight' column
bigmart_data['Item_Weight'].mean()

# filling the missing values in "Item_Weight" column with "Mean" value
bigmart_data['Item_Weight'].fillna(bigmart_data['Item_Weight'].mean(), inplace=True)

# Checking for missing values
bigmart_data.isnull().sum()

"""Replacing the missing values in "Outlet_Size" column with Mode"""

mode_of_outlet_size = bigmart_data.pivot_table(values='Outlet_Size', columns='Outlet_Type', aggfunc=lambda x: x.mode().iat[0])

print(mode_of_outlet_size)

missing_values = bigmart_data['Outlet_Size'].isnull()

print(missing_values)

bigmart_data.loc[missing_values, 'Outlet_Size'] = bigmart_data.loc[missing_values, 'Outlet_Type'].apply(lambda x: mode_of_outlet_size[x])

# Checking for missing values
bigmart_data.isnull().sum()

"""Data Analysis"""

# statistical measures about the data
bigmart_data.describe()

"""Numerical Features"""

sns.set()

# Item_Weight distribution
plt.figure(figsize=(6,6))
sns.distplot(bigmart_data['Item_Weight'])
plt.show

# Item_Visibility distribution
plt.figure(figsize=(6,6))
sns.distplot(bigmart_data['Item_Visibility'])
plt.show

# Item_MRP distribution
plt.figure(figsize=(6,6))
sns.distplot(bigmart_data['Item_MRP'])
plt.show

# Item_Outlet_Sales distribution
plt.figure(figsize=(6,6))
sns.distplot(bigmart_data['Item_Outlet_Sales'])
plt.show

# Outlet_Establishment_Year column
plt.figure(figsize=(6,6))
sns.countplot(x='Outlet_Establishment_Year', data=bigmart_data)
plt.show()

"""Catagorical Features"""

# Item_Fat_Content column
plt.figure(figsize=(6,6))
sns.countplot(x='Item_Fat_Content', data=bigmart_data)
plt.show()

# Item_Type column
plt.figure(figsize=(30,6))
sns.countplot(x='Item_Type', data=bigmart_data)
plt.show()

# Outlet_Size column
plt.figure(figsize=(6,6))
sns.countplot(x='Outlet_Size', data=bigmart_data)
plt.title('Outlet_Size count')
plt.show()

"""Data Pre-Processing"""

bigmart_data.head()

bigmart_data['Item_Fat_Content'].value_counts()

bigmart_data.replace({'Item_Fat_Content':{'low fat':'Low Fat','LF':'Low Fat', 'reg' : 'Regular'}}, inplace = True)

bigmart_data['Item_Fat_Content'].value_counts()

"""Label Encoding"""

encoder = LabelEncoder()

"""
    Item_Identifier
    Item_Fat_Content
    Item_Type
    Outlet_Identifier
    Outlet_Size
    Outlet_Location_Type
    Outlet_Type
"""

bigmart_data['Item_Identifier'] = encoder.fit_transform(bigmart_data['Item_Identifier'])

bigmart_data['Item_Fat_Content'] = encoder.fit_transform(bigmart_data['Item_Fat_Content'])

bigmart_data['Item_Type'] = encoder.fit_transform(bigmart_data['Item_Type'])

bigmart_data['Outlet_Identifier'] = encoder.fit_transform(bigmart_data['Outlet_Identifier'])

bigmart_data['Outlet_Size'] = encoder.fit_transform(bigmart_data['Outlet_Size'])

bigmart_data['Outlet_Location_Type'] = encoder.fit_transform(bigmart_data['Outlet_Location_Type'])

bigmart_data['Outlet_Type'] = encoder.fit_transform(bigmart_data['Outlet_Type'])

bigmart_data.head()

"""Splitting features and target"""

X=bigmart_data.drop(columns='Item_Outlet_Sales', axis=1)
Y=bigmart_data['Item_Outlet_Sales']

print(X)

print(Y)

"""Splitting the data into training data and testing data"""

X_train,X_test,Y_train,Y_test = train_test_split(X,Y, test_size = 0.2, random_state=2)

print(X.shape,X_train.shape,X_test.shape)

"""Model Training

XGBoost Regressor
"""

regressor = XGBRegressor()

regressor.fit(X_train,Y_train)

"""Evaluation"""

# prediction on training data
training_data_prediction = regressor.predict(X_train)

# R Squared Value
r2_train = metrics.r2_score(Y_train, training_data_prediction)

print('R Squared Value =', r2_train)

# prediction on test data
test_data_prediction = regressor.predict(X_test)

# R Squared Value
r2_test = metrics.r2_score(Y_test, test_data_prediction)

print('R Squared Value =', r2_test)

